{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Watson OpenScale and Watson Machine Learning "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This notebook should be run in a Watson Studio project, using **Default Spark Python 3.6** runtime environment. It assumes the required services have already been provisioned and will require service credentials and a Cloud API key to access the following Cloud services:\n  * Watson Machine Learning\n  * Watson OpenScale\n  \nThe notebook will deploy a German Credit Risk model and then configure Watson OpenScale to subscribe the deployed model."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Spark Validation"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20191112170248-0001\nKERNEL_ID = 455ff96e-d557-4274-a6e0-68cfa6067d85\n"
                }
            ],
            "source": "try:\n    from pyspark.sql import SparkSession\nexcept:\n    print('Error: Spark runtime is missing. If you are using Watson Studio change the notebook runtime to Spark.')\n    raise "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Dependency Setup"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\u001b[31mtensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\n\u001b[31mbotocore 1.12.82 has requirement urllib3<1.25,>=1.20, but you'll have urllib3 1.25.7 which is incompatible.\u001b[0m\n\u001b[31mException:\nTraceback (most recent call last):\n  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/cli/base_command.py\", line 176, in main\n    status = self.run(options, args)\n  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 441, in run\n    options.target_dir, target_temp_dir, options.upgrade\n  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 492, in _handle_target_dir\n    shutil.rmtree(target_item_dir)\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 486, in rmtree\n    _rmtree_safe_fd(fd, path, onerror)\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 428, in _rmtree_safe_fd\n    onerror(os.rmdir, fullname, sys.exc_info())\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 426, in _rmtree_safe_fd\n    os.rmdir(name, dir_fd=topfd)\nOSError: [Errno 39] Directory not empty: 'random'\u001b[0m\nSuccessfully installed certifi-2019.9.11 chardet-3.0.4 h5py-2.10.0 ibm-ai-openscale-2.1.17 idna-2.8 numpy-1.17.4 pandas-0.25.3 python-dateutil-2.8.1 pytz-2019.3 requests-2.22.0 six-1.13.0 tabulate-0.8.5 urllib3-1.25.7\n\u001b[31mtensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\n\u001b[31mbotocore 1.12.82 has requirement urllib3<1.25,>=1.20, but you'll have urllib3 1.25.7 which is incompatible.\u001b[0m\n\u001b[31mException:\nTraceback (most recent call last):\n  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/cli/base_command.py\", line 176, in main\n    status = self.run(options, args)\n  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 441, in run\n    options.target_dir, target_temp_dir, options.upgrade\n  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 492, in _handle_target_dir\n    shutil.rmtree(target_item_dir)\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 486, in rmtree\n    _rmtree_safe_fd(fd, path, onerror)\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 424, in _rmtree_safe_fd\n    _rmtree_safe_fd(dirfd, fullname, onerror)\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 444, in _rmtree_safe_fd\n    onerror(os.unlink, fullname, sys.exc_info())\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 442, in _rmtree_safe_fd\n    os.unlink(name, dir_fd=topfd)\nOSError: [Errno 16] Device or resource busy: '.nfs0000000007c4d1f60000029d'\u001b[0m\nSuccessfully installed certifi-2019.9.11 chardet-3.0.4 docutils-0.15.2 ibm-cos-sdk-2.5.5 ibm-cos-sdk-core-2.5.5 ibm-cos-sdk-s3transfer-2.5.5 idna-2.8 jmespath-0.9.4 lomond-0.3.3 numpy-1.17.4 pandas-0.25.3 python-dateutil-2.8.1 pytz-2019.3 requests-2.22.0 six-1.13.0 tabulate-0.8.5 tqdm-4.38.0 urllib3-1.25.7 watson-machine-learning-client-1.0.376\n"
                }
            ],
            "source": "!pip install --upgrade ibm-ai-openscale --no-cache | tail -n 1\n!pip install --upgrade watson-machine-learning-client | tail -n 1"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Service Credentials\n\nWe will be building a machine learning model below and deploying it to the Watson Machine Learning service. To interact with the service, you will need credentials for your Watson Machine Learning service instance. Copy and paste your WML credentials into the cell below."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "WML_CREDENTIALS = {\n  \"apikey\": \"XycYiznO-hJ4nideySgm4bHOjuzaCAWuU8WNgOpWwms_\",\n  \"iam_apikey_description\": \"Auto-generated for key 40fca5a1-ec33-48c6-a74e-7c8a4f06e6dd\",\n  \"iam_apikey_name\": \"Service credentials-1\",\n  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/93eb3babe6a441f4802534fa099afa74::serviceid:ServiceId-8c0d503c-4df3-4c11-ba95-04e628e079c4\",\n  \"instance_id\": \"e3da0525-31af-4c9e-a2d2-3aad877dd536\",\n  \"url\": \"https://us-south.ml.cloud.ibm.com\"\n}"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "To interact with the Watson OpenScale service, we will use the Cloud API Key to find the service instances GUID."
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "CLOUD_API_KEY = \"VKrmMglnKS33gsLg9d5Tica9PwpSpA9Uf_1ZquX1dI6_\""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Model Parameters\n\nWe will use the following name for the Scikit model and the deployment to WML."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "MODEL_NAME = \"Spark German Risk Model\"\nDEPLOYMENT_NAME = \"Spark German Risk Deployment\""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Deploy a model to Watson Machine Learning\n\nIn this section you will learn how to train Scikit-learn model and next deploy it as web-service using Watson Machine Learning service."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Load and explore the training data"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "-rw-r--r-- 1 spark 4294967294 674K Nov 12 17:03 german_credit_data_biased_training.csv\nNumber of records:  5000\nNumber of columns:  21\nroot\n |-- CheckingStatus: string (nullable = true)\n |-- LoanDuration: integer (nullable = true)\n |-- CreditHistory: string (nullable = true)\n |-- LoanPurpose: string (nullable = true)\n |-- LoanAmount: integer (nullable = true)\n |-- ExistingSavings: string (nullable = true)\n |-- EmploymentDuration: string (nullable = true)\n |-- InstallmentPercent: integer (nullable = true)\n |-- Sex: string (nullable = true)\n |-- OthersOnLoan: string (nullable = true)\n |-- CurrentResidenceDuration: integer (nullable = true)\n |-- OwnsProperty: string (nullable = true)\n |-- Age: integer (nullable = true)\n |-- InstallmentPlans: string (nullable = true)\n |-- Housing: string (nullable = true)\n |-- ExistingCreditsCount: integer (nullable = true)\n |-- Job: string (nullable = true)\n |-- Dependents: integer (nullable = true)\n |-- Telephone: string (nullable = true)\n |-- ForeignWorker: string (nullable = true)\n |-- Risk: string (nullable = true)\n\n"
                },
                {
                    "data": {
                        "text/plain": "Row(CheckingStatus='0_to_200', LoanDuration=31, CreditHistory='credits_paid_to_date', LoanPurpose='other', LoanAmount=1889, ExistingSavings='100_to_500', EmploymentDuration='less_1', InstallmentPercent=3, Sex='female', OthersOnLoan='none', CurrentResidenceDuration=3, OwnsProperty='savings_insurance', Age=32, InstallmentPlans='none', Housing='own', ExistingCreditsCount=1, Job='skilled', Dependents=1, Telephone='none', ForeignWorker='yes', Risk='No Risk')"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import pandas as pd\nfrom IPython.utils import io\n\nwith io.capture_output() as captured:\n    !wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_data_biased_training.csv  -O german_credit_data_biased_training.csv\n!ls -lh german_credit_data_biased_training.csv\n\nspark = SparkSession.builder.getOrCreate()\ndf_data = spark.read.csv(path=\"german_credit_data_biased_training.csv\", sep=\",\", header=True, inferSchema=True)\n\nprint('Number of records: ', str(df_data.count()))\nprint('Number of columns: ', len(df_data.columns))\ndf_data.printSchema()\ndf_data.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As you can see, we have 5000 records in this data set and the data contains twenty one fields. `Risk` field is the one you would like to predict using feedback data."
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "aggregation": "COUNT",
                        "binsize": "10",
                        "chartsize": "100",
                        "handlerId": "barChart",
                        "keyFields": "Age",
                        "rendererId": "brunel",
                        "valueFields": ""
                    }
                }
            },
            "outputs": [],
            "source": "# Optional, use PixieDust to visualize the data\n#import pixiedust\n\n# display(df_data)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Build a pre-trained model\n\nWe could take our data and commence with data preparation to build and train the machine learning pipeline. However, we are just going to deploy a pre-trained model (https://github.com/pmservice/wml-sample-models/tree/master/spark/credit-risk)"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "-rw-r--r-- 1 spark 4294967294 37K Nov 12 17:03 credit-risk-model.tgz\nmetadata  stages\n"
                }
            ],
            "source": "with io.capture_output() as captured:\n    !wget https://github.com/pmservice/wml-sample-models/blob/master/spark/credit-risk/model/credit-risk-model.tgz?raw=true  -O credit-risk-model.tgz\n!ls -lh credit-risk-model.tgz\n\n!rm -rf credit-risk-model\n!mkdir credit-risk-model\n!tar -xf credit-risk-model.tgz -C credit-risk-model\n!ls credit-risk-model"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The code below imports our Random Forest Classifier which is a Spark pipeline model, setting up string indexers for the categorical features and the label column."
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml import Pipeline, Model, PipelineModel\n\nmodel = PipelineModel.load(\"credit-risk-model\")\npipeline = Pipeline( stages = model.stages )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Publish the model"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this section, the notebook uses the supplied Watson Machine Learning credentials to save the model (including the pipeline) to the WML instance. Previous versions of the model are removed so that the notebook can be run again, resetting all data for another demo."
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n\nwml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)\n# wml_client.service_instance.get_details()"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Models before removal of Deployment Name:  Spark German Risk Deployment\n------------------------------------  -----------------------  ------------------------  ---------\nGUID                                  NAME                     CREATED                   FRAMEWORK\ne5eed7fe-1baf-40a6-a305-79fb75dba167  Spark German Risk Model  2019-11-12T15:17:54.004Z  mllib-2.3\n------------------------------------  -----------------------  ------------------------  ---------\nDeleting deployment id 597073f0-3efc-4280-b970-5a70acb9dd9f\nDeleting model id e5eed7fe-1baf-40a6-a305-79fb75dba167\nModels after removal of Deployment Name:  Spark German Risk Deployment\n----  ----  -------  ---------\nGUID  NAME  CREATED  FRAMEWORK\n----  ----  -------  ---------\n"
                }
            ],
            "source": "print(\"Models before removal of Deployment Name: \", DEPLOYMENT_NAME )\nwml_client.repository.list_models()\nmodel_deployment_ids = wml_client.deployments.get_uids()\nfor deployment_id in model_deployment_ids:\n    deployment = wml_client.deployments.get_details(deployment_id)\n    model_id = deployment['entity']['deployable_asset']['guid']\n    if deployment['entity']['name'] == DEPLOYMENT_NAME:\n        print('Deleting deployment id', deployment_id)\n        wml_client.deployments.delete(deployment_id)\n        print('Deleting model id', model_id)\n        wml_client.repository.delete(model_id)\n\nprint(\"Models after removal of Deployment Name: \", DEPLOYMENT_NAME )\nwml_client.repository.list_models()"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "-rw-r--r-- 1 spark 4294967294 14K Nov 12 17:04 credit-risk-meta.json\r\n"
                }
            ],
            "source": "import json\n\nwith io.capture_output() as captured:\n    !wget https://raw.githubusercontent.com/pmservice/wml-sample-models/master/spark/credit-risk/meta/credit-risk-meta.json -O credit-risk-meta.json\n!ls -lh credit-risk-meta.json\nwith open('credit-risk-meta.json') as f:\n    [training_data_reference, *_] = json.load(f)['model_meta']['training_data_reference']\nwith open('credit-risk-meta.json') as f2:\n    [metrics, *_] = json.load(f2)['model_meta']['evaluation']['metrics']\n\nmodel_props = {\n    wml_client.repository.ModelMetaNames.NAME: \"{}\".format(MODEL_NAME),\n    wml_client.repository.ModelMetaNames.EVALUATION_METHOD: \"binary\",\n    wml_client.repository.ModelMetaNames.TRAINING_DATA_REFERENCE: training_data_reference,\n    wml_client.repository.ModelMetaNames.EVALUATION_METRICS: [\n        {\n           \"name\": \"areaUnderROC\",\n           \"value\": metrics['value'],\n           \"threshold\": 0.7\n        }\n    ]\n}"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Storing model ...\nDone\n------------------------------------  -----------------------  ------------------------  ---------\nGUID                                  NAME                     CREATED                   FRAMEWORK\n0e47d7a8-6157-48b0-ac8a-71f05aa9cceb  Spark German Risk Model  2019-11-12T17:04:51.177Z  mllib-2.3\n------------------------------------  -----------------------  ------------------------  ---------\nModel ID:  0e47d7a8-6157-48b0-ac8a-71f05aa9cceb\n"
                }
            ],
            "source": "wml_models = wml_client.repository.get_details()\nmodel_uid = None\nfor model_in in wml_models['models']['resources']:\n    if MODEL_NAME == model_in['entity']['name']:\n        model_uid = model_in['metadata']['guid']\n        break\n\nif model_uid is None:\n    print(\"Storing model ...\")    \n    published_model_details = wml_client.repository.store_model(model=model, meta_props=model_props, training_data=df_data, pipeline=pipeline)\n    model_uid = wml_client.repository.get_model_uid(published_model_details)\n    print(\"Done\")\n    \nwml_client.repository.list_models()\nprint(\"Model ID: \", model_uid)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Deploy the model\nThe next section of the notebook deploys the model as a RESTful web service in Watson Machine Learning. The deployed model will have a scoring URL you can use to send data to the model for predictions."
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Deploying model...\n\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '0e47d7a8-6157-48b0-ac8a-71f05aa9cceb' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_IN_PROGRESS.\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='95ab5f08-df78-4432-8f3a-d0835a875832'\n------------------------------------------------------------------------------------------------\n\n\nModel id: 0e47d7a8-6157-48b0-ac8a-71f05aa9cceb\nDeployment id: 95ab5f08-df78-4432-8f3a-d0835a875832\nScoring URL: https://us-south.ml.cloud.ibm.com/v3/wml_instances/e3da0525-31af-4c9e-a2d2-3aad877dd536/deployments/95ab5f08-df78-4432-8f3a-d0835a875832/online\n"
                }
            ],
            "source": "wml_deployments = wml_client.deployments.get_details()\ndeployment_uid = None\nfor deployment in wml_deployments['resources']:\n    if DEPLOYMENT_NAME == deployment['entity']['name']:\n        deployment_uid = deployment['metadata']['guid']        \n        scoring_url = deployment_in['entity']['scoring_url']\n        break\n\nif deployment_uid is None:\n    print(\"Deploying model...\")\n    deployment = wml_client.deployments.create(artifact_uid=model_uid, name=DEPLOYMENT_NAME, asynchronous=False)\n    deployment_uid = wml_client.deployments.get_uid(deployment)\n    scoring_url = wml_client.deployments.get_scoring_url(deployment)\n    \nprint(\"Model id: {}\".format(model_uid))\nprint(\"Deployment id: {}\".format(deployment_uid))\nprint(\"Scoring URL: {}\".format(scoring_url))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Test the scoring endpoint\nWe can test the deployed model endpoint with some sample data."
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Scoring result: \n fields: ['CheckingStatus', 'LoanDuration', 'CreditHistory', 'LoanPurpose', 'LoanAmount', 'ExistingSavings', 'EmploymentDuration', 'InstallmentPercent', 'Sex', 'OthersOnLoan', 'CurrentResidenceDuration', 'OwnsProperty', 'Age', 'InstallmentPlans', 'Housing', 'ExistingCreditsCount', 'Job', 'Dependents', 'Telephone', 'ForeignWorker', 'CheckingStatus_IX', 'CreditHistory_IX', 'EmploymentDuration_IX', 'ExistingSavings_IX', 'ForeignWorker_IX', 'Housing_IX', 'InstallmentPlans_IX', 'Job_IX', 'LoanPurpose_IX', 'OthersOnLoan_IX', 'OwnsProperty_IX', 'Sex_IX', 'Telephone_IX', 'features', 'rawPrediction', 'probability', 'prediction', 'predictedLabel'] \n values: \n  ['no_checking', 13, 'credits_paid_to_date', 'car_new', 1343, '100_to_500', '1_to_4', 2, 'female', 'none', 3, 'savings_insurance', 46, 'none', 'own', 2, 'skilled', 1, 'none', 'yes', 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, [21, [1, 3, 5, 13, 14, 15, 16, 17, 18, 19, 20], [1.0, 1.0, 1.0, 13.0, 1343.0, 2.0, 3.0, 13.0, 46.0, 2.0, 1.0]], [14.099479641547418, 5.900520358452582], [0.7049739820773709, 0.29502601792262906], 0.0, 'No Risk']\n"
                }
            ],
            "source": "fields = [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\",\n                  \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\",\n                  \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n                  \"Telephone\", \"ForeignWorker\"]\nvalues = [\n            [\"no_checking\", 13, \"credits_paid_to_date\", \"car_new\", 1343, \"100_to_500\", \"1_to_4\", 2, \"female\", \"none\", 3,\n             \"savings_insurance\", 46, \"none\", \"own\", 2, \"skilled\", 1, \"none\", \"yes\"]\n        ]\n\nscoring_payload = {\"fields\": fields, \"values\": values}\npredictions = wml_client.deployments.score(scoring_url, scoring_payload)\nprint('Scoring result:', '\\n fields:', predictions['fields'], '\\n values: \\n ', '\\n  '.join([str(elem) for elem in predictions['values']]))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Configure Watson OpenScale\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Get Watson OpenScale GUID\n\nEach instance of OpenScale has a unique ID. We can get this value using the Cloud API key specified at the beginning of the notebook.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Watson OpenScale GUID: 60143291-0ba2-4347-950b-9038fde2a8f8\nWatson OpenScale Python Client Version: 2.1.17\n"
                }
            ],
            "source": "from ibm_ai_openscale import APIClient\nfrom ibm_ai_openscale.utils import get_instance_guid\n\nWOS_GUID = get_instance_guid(api_key=CLOUD_API_KEY)\nWOS_CREDENTIALS = {\n    \"instance_guid\": WOS_GUID,\n    \"apikey\": CLOUD_API_KEY,\n    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n}\n\nif WOS_GUID is None:\n    print('Watson OpenScale GUID NOT FOUND')\nelse:\n    print(\"Watson OpenScale GUID: {}\".format(WOS_GUID))\n\nwos_client = APIClient(aios_credentials=WOS_CREDENTIALS)\nprint(\"Watson OpenScale Python Client Version: {}\".format(wos_client.version))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Create schema and datamart\n\nWatson OpenScale uses a database to store payload logs and calculated metrics. Databases for PostgreSQL, Db2 Warehouse, or a free internal verison of PostgreSQL can be used to create a datamart for OpenScale.\n\nThis notebook will use the free, internal lite database. If you have previously configured OpenScale, it will use your existing datamart, and not interfere with any models you are currently monitoring. Do not update the cell below.\n\nIf you previously configured OpenScale to use the free internal version of PostgreSQL, you can switch to a new datamart using a paid database service. If you would like to delete the internal PostgreSQL configuration and create a new one using service credentials supplied in the cell above, set the KEEP_MY_INTERNAL_POSTGRES variable below to False below. In this case, the notebook will remove your existing internal PostgreSQL datamart and create a new one with the supplied credentials. NO DATA MIGRATION WILL OCCUR.\n\nPrior instances of the German Credit model will be removed from OpenScale monitoring.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "KEEP_MY_INTERNAL_POSTGRES = True"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Using existing internal datamart.\n"
                }
            ],
            "source": "try:\n    data_mart_details = wos_client.data_mart.get_details()\n    if 'internal_database' in data_mart_details and data_mart_details['internal_database']:\n        if KEEP_MY_INTERNAL_POSTGRES:\n            print('Using existing internal datamart.')\n        else:\n            print('Resetting internal datamart')\n            wos_client.data_mart.delete(force=True)\n            wos_client.data_mart.setup(internal_db=True)\n    else:\n        print('Using existing external datamart')\nexcept:\n    print('Setting up internal datamart')\n    wos_client.data_mart.setup(internal_db=True)"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'database_configuration': {},\n 'internal_database': True,\n 'internal_database_pool': 'icd-psql',\n 'service_instance_crn': 'crn:v1:bluemix:public:aiopenscale:us-south:a/93eb3babe6a441f4802534fa099afa74:60143291-0ba2-4347-950b-9038fde2a8f8::',\n 'status': {'state': 'active'}}"
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "data_mart_details = wos_client.data_mart.get_details()\ndata_mart_details"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Bind machine learning engines\n\nWatson OpenScale needs to be bound to the Watson Machine Learning instance to capture payload data into and out of the model. If this binding already exists, this code will output a warning message and use the existing binding.\n\nNote: You can bind more than one engine instance if needed by calling ai_client.data_mart.bindings.add method. Next, you can refer to particular binding using binding_uid."
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Warning during bind instance.\nStatus code: 409, body: {\"errors\":[{\"code\":\"AIQCS0010W\",\"message\":\"Service Binding with this id is already defined\"}],\"trace\":\"MDczNzRiN2QtNzE2NC00ODY5LWI5MmYtMTc4NmQ5NWJhNDVh\"}\nModel Serve Engine Binding ID: e3da0525-31af-4c9e-a2d2-3aad877dd536\n"
                }
            ],
            "source": "from ibm_ai_openscale.engines import *\n\nbinding_uid = wos_client.data_mart.bindings.add('WML instance', WatsonMachineLearningInstance(WML_CREDENTIALS))\nif binding_uid is None:\n    binding_uid = wos_client.data_mart.bindings.get_details()['service_bindings'][0]['metadata']['guid']\nbindings_details = wos_client.data_mart.bindings.get_details()\nprint(\"Model Serve Engine Binding ID: {}\".format(binding_uid))"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<HTML>\n        <body>\n            <h3>Service bindings</h3>\n            <table style='border: 1px solid #dddddd; font-family: Courier'>\n                <th style='border: 1px solid #dddddd'>uid</th><th style='border: 1px solid #dddddd'>name</th><th style='border: 1px solid #dddddd'>service_type</th><th style='border: 1px solid #dddddd'>created</th>\n                <tr><td style='border: 1px solid #dddddd'>e3da0525-31af-4c9e-a2d2-3aad877dd536</td><td style='border: 1px solid #dddddd'>WML instance</td><td style='border: 1px solid #dddddd'>watson_machine_learning</td><td style='border: 1px solid #dddddd'>2019-11-12T15:18:45.636Z</td></tr>\n            </table>\n        </body>\n        </HTML>",
                        "text/plain": "<IPython.core.display.HTML object>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": "<HTML>\n        <body>\n            <h3>Available assets</h3>\n            <table style='border: 1px solid #dddddd; font-family: Courier'>\n                <th style='border: 1px solid #dddddd'>source_uid</th><th style='border: 1px solid #dddddd'>name</th><th style='border: 1px solid #dddddd'>created</th><th style='border: 1px solid #dddddd'>type</th><th style='border: 1px solid #dddddd'>frameworks</th><th style='border: 1px solid #dddddd'>binding_uid</th><th style='border: 1px solid #dddddd'>is_subscribed</th>\n                <tr><td style='border: 1px solid #dddddd'>0e47d7a8-6157-48b0-ac8a-71f05aa9cceb</td><td style='border: 1px solid #dddddd'>Spark German Risk Model</td><td style='border: 1px solid #dddddd'>2019-11-12T17:05:03.457Z</td><td style='border: 1px solid #dddddd'>model</td><td style='border: 1px solid #dddddd'>mllib-2.3</td><td style='border: 1px solid #dddddd'>e3da0525-31af-4c9e-a2d2-3aad877dd536</td><td style='border: 1px solid #dddddd'>False</td></tr>\n            </table>\n        </body>\n        </HTML>",
                        "text/plain": "<IPython.core.display.HTML object>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": "wos_client.data_mart.bindings.list()\nwos_client.data_mart.bindings.list_assets()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Subscriptions\n\nNext we will subscribe OpenScale to the deployed model so that we can configure our monitors. We will first remove previous subscriptions to the German Credit model to refresh the monitors with the new model and new data. Then we will create the model subscription in OpenScale using the Python client API. Note that we need to provide the model unique identifier, and some information about the model itself."
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": "subscriptions_uids = wos_client.data_mart.subscriptions.get_uids()\nfor subscription in subscriptions_uids:\n    sub_name = wos_client.data_mart.subscriptions.get_details(subscription)['entity']['asset']['name']\n    if sub_name == MODEL_NAME:\n        wos_client.data_mart.subscriptions.delete(subscription)\n        print('Deleted existing subscription for', MODEL_NAME)"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": "from ibm_ai_openscale.supporting_classes.enums import *\n\nsubscription = wos_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n    model_uid,\n    problem_type=ProblemType.BINARY_CLASSIFICATION,\n    input_data_type=InputDataType.STRUCTURED,\n    label_column='Risk',\n    prediction_column='predictedLabel',\n    probability_column='probability',\n    feature_columns = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"],\n    categorical_columns = [\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"]\n))\n\nif subscription is None:\n    print('Subscription already exists; get the existing one')\n    subscriptions_uids = wos_client.data_mart.subscriptions.get_uids()\n    for sub in subscriptions_uids:\n        if wos_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n            subscription = wos_client.data_mart.subscriptions.get(sub)"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<HTML>\n        <body>\n            <h3>Subscriptions</h3>\n            <table style='border: 1px solid #dddddd; font-family: Courier'>\n                <th style='border: 1px solid #dddddd'>uid</th><th style='border: 1px solid #dddddd'>name</th><th style='border: 1px solid #dddddd'>type</th><th style='border: 1px solid #dddddd'>binding_uid</th><th style='border: 1px solid #dddddd'>created</th>\n                <tr><td style='border: 1px solid #dddddd'>1b906143-6525-47dc-9b41-ea6ac66fd1c1</td><td style='border: 1px solid #dddddd'>Spark German Risk Model</td><td style='border: 1px solid #dddddd'>model</td><td style='border: 1px solid #dddddd'>e3da0525-31af-4c9e-a2d2-3aad877dd536</td><td style='border: 1px solid #dddddd'>2019-11-12T17:05:29.583Z</td></tr>\n            </table>\n        </body>\n        </HTML>",
                        "text/plain": "<IPython.core.display.HTML object>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": "<HTML>\n        <body>\n            <h3>Available assets</h3>\n            <table style='border: 1px solid #dddddd; font-family: Courier'>\n                <th style='border: 1px solid #dddddd'>source_uid</th><th style='border: 1px solid #dddddd'>name</th><th style='border: 1px solid #dddddd'>created</th><th style='border: 1px solid #dddddd'>type</th><th style='border: 1px solid #dddddd'>frameworks</th><th style='border: 1px solid #dddddd'>binding_uid</th><th style='border: 1px solid #dddddd'>is_subscribed</th>\n                <tr><td style='border: 1px solid #dddddd'>0e47d7a8-6157-48b0-ac8a-71f05aa9cceb</td><td style='border: 1px solid #dddddd'>Spark German Risk Model</td><td style='border: 1px solid #dddddd'>2019-11-12T17:05:03.457Z</td><td style='border: 1px solid #dddddd'>model</td><td style='border: 1px solid #dddddd'>mllib-2.3</td><td style='border: 1px solid #dddddd'>e3da0525-31af-4c9e-a2d2-3aad877dd536</td><td style='border: 1px solid #dddddd'>True</td></tr>\n            </table>\n        </body>\n        </HTML>",
                        "text/plain": "<IPython.core.display.HTML object>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": "subscriptions_uids = wos_client.data_mart.subscriptions.get_uids()\nsubscription_details = subscription.get_details()\n#print(subscriptions_uids)\n#print(subscription_details)\n\nwos_client.data_mart.subscriptions.list()\nwos_client.data_mart.bindings.list_assets()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Score the model so we can configure monitors\n\nNow that the WML service has been bound and the subscription has been created, we need to send a request to the model before we configure OpenScale. This allows OpenScale to create a payload log in the datamart with the correct schema, so it can capture data coming into and out of the model."
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Single record scoring result: \n fields: ['CheckingStatus', 'LoanDuration', 'CreditHistory', 'LoanPurpose', 'LoanAmount', 'ExistingSavings', 'EmploymentDuration', 'InstallmentPercent', 'Sex', 'OthersOnLoan', 'CurrentResidenceDuration', 'OwnsProperty', 'Age', 'InstallmentPlans', 'Housing', 'ExistingCreditsCount', 'Job', 'Dependents', 'Telephone', 'ForeignWorker', 'CheckingStatus_IX', 'CreditHistory_IX', 'EmploymentDuration_IX', 'ExistingSavings_IX', 'ForeignWorker_IX', 'Housing_IX', 'InstallmentPlans_IX', 'Job_IX', 'LoanPurpose_IX', 'OthersOnLoan_IX', 'OwnsProperty_IX', 'Sex_IX', 'Telephone_IX', 'features', 'rawPrediction', 'probability', 'prediction', 'predictedLabel'] \n values:  ['no_checking', 13, 'credits_paid_to_date', 'car_new', 1343, '100_to_500', '1_to_4', 2, 'female', 'none', 3, 'savings_insurance', 46, 'none', 'own', 2, 'skilled', 1, 'none', 'yes', 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, [21, [1, 3, 5, 13, 14, 15, 16, 17, 18, 19, 20], [1.0, 1.0, 1.0, 13.0, 1343.0, 2.0, 3.0, 13.0, 46.0, 2.0, 1.0]], [14.099479641547418, 5.900520358452582], [0.7049739820773709, 0.29502601792262906], 0.0, 'No Risk']\n"
                }
            ],
            "source": "import datetime\nimport time\n\ntime.sleep(10)\n\nfields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\nvalues = [\n  [\"no_checking\",13,\"credits_paid_to_date\",\"car_new\",1343,\"100_to_500\",\"1_to_4\",2,\"female\",\"none\",3,\"savings_insurance\",46,\"none\",\"own\",2,\"skilled\",1,\"none\",\"yes\"],\n  [\"no_checking\",24,\"prior_payments_delayed\",\"furniture\",4567,\"500_to_1000\",\"1_to_4\",4,\"male\",\"none\",4,\"savings_insurance\",36,\"none\",\"free\",2,\"management_self-employed\",1,\"none\",\"yes\"],\n  [\"0_to_200\",26,\"all_credits_paid_back\",\"car_new\",863,\"less_100\",\"less_1\",2,\"female\",\"co-applicant\",2,\"real_estate\",38,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n  [\"0_to_200\",14,\"no_credits\",\"car_new\",2368,\"less_100\",\"1_to_4\",3,\"female\",\"none\",3,\"real_estate\",29,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n  [\"0_to_200\",4,\"no_credits\",\"car_new\",250,\"less_100\",\"unemployed\",2,\"female\",\"none\",3,\"real_estate\",23,\"none\",\"rent\",1,\"management_self-employed\",1,\"none\",\"yes\"],\n  [\"no_checking\",17,\"credits_paid_to_date\",\"car_new\",832,\"100_to_500\",\"1_to_4\",2,\"male\",\"none\",2,\"real_estate\",42,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n  [\"no_checking\",33,\"outstanding_credit\",\"appliances\",5696,\"unknown\",\"greater_7\",4,\"male\",\"co-applicant\",4,\"unknown\",54,\"none\",\"free\",2,\"skilled\",1,\"yes\",\"yes\"],\n  [\"0_to_200\",13,\"prior_payments_delayed\",\"retraining\",1375,\"100_to_500\",\"4_to_7\",3,\"male\",\"none\",3,\"real_estate\",37,\"none\",\"own\",2,\"management_self-employed\",1,\"none\",\"yes\"]\n]\n\npayload_scoring = {\"fields\": fields,\"values\": values}\nscoring_response = wml_client.deployments.score(scoring_url, payload_scoring)\n\nprint('Single record scoring result:', '\\n fields:', scoring_response['fields'], '\\n values: ', scoring_response['values'][0])"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Number of records in payload table (should be 8):  0\n"
                },
                {
                    "data": {
                        "text/html": "<HTML>\n        <body>\n            <h3>Payload_1b906143-6525-47dc-9b41-ea6ac66fd1c1 (binding_id=e3da0525-31af-4c9e-a2d2-3aad877dd536, subscription_id=1b906143-6525-47dc-9b41-ea6ac66fd1c1)</h3>\n            <table style='border: 1px solid #dddddd; font-family: Courier'>\n                <th style='border: 1px solid #dddddd'>CheckingStatus</th><th style='border: 1px solid #dddddd'>LoanDuration</th><th style='border: 1px solid #dddddd'>CreditHistory</th><th style='border: 1px solid #dddddd'>LoanPurpose</th><th style='border: 1px solid #dddddd'>LoanAmount</th><th style='border: 1px solid #dddddd'>ExistingSavings</th><th style='border: 1px solid #dddddd'>EmploymentDuration</th><th style='border: 1px solid #dddddd'>InstallmentPercent</th><th style='border: 1px solid #dddddd'>Sex</th><th style='border: 1px solid #dddddd'>OthersOnLoan</th><th style='border: 1px solid #dddddd'>CurrentResidenceDuration</th><th style='border: 1px solid #dddddd'>OwnsProperty</th><th style='border: 1px solid #dddddd'>Age</th><th style='border: 1px solid #dddddd'>InstallmentPlans</th><th style='border: 1px solid #dddddd'>Housing</th><th style='border: 1px solid #dddddd'>ExistingCreditsCount</th><th style='border: 1px solid #dddddd'>Job</th><th style='border: 1px solid #dddddd'>Dependents</th><th style='border: 1px solid #dddddd'>Telephone</th><th style='border: 1px solid #dddddd'>ForeignWorker</th><th style='border: 1px solid #dddddd'>prediction</th><th style='border: 1px solid #dddddd'>probability</th><th style='border: 1px solid #dddddd'>prediction_probability</th><th style='border: 1px solid #dddddd'>scoring_id</th><th style='border: 1px solid #dddddd'>scoring_timestamp</th><th style='border: 1px solid #dddddd'>deployment_id</th><th style='border: 1px solid #dddddd'>asset_revision</th>\n                \n            </table>\n        </body>\n        </HTML>",
                        "text/plain": "<IPython.core.display.HTML object>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": "# Payload will be logged in the datamart. Re-run this cell if there are no results in the table.\nprint('Number of records in payload table (should be 8): ', subscription.payload_logging.get_records_count())\nsubscription.payload_logging.show_table()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Next steps\n\nOpenScale is ready to monitor the model. We can configure various types of monitors (quality, fairness, explainability, drift, etc) using either the UI or through a python client. \n\n__Return to the workshop instruction book.__\n\n  \n## Credits\n\nThis notebook was adapted from the following sources:\n* [Monitor Models Code Pattern](https://github.com/IBM/monitor-wml-model-with-watson-openscale)\n* [OpenScale Labs](https://github.com/pmservice/OpenScale-Labs)\n* [OpenScale Tutorials](https://github.com/pmservice/ai-openscale-tutorials)\n\n#### Original Authors\n* Eric Martens, is a technical specialist having expertise in analysis and description of business processes, and their translation into functional and non-functional IT requirements. He acts as the interpreter between the worlds of IT and business.\n* Lukasz Cmielowski, PhD, is an Automation Architect and Data Scientist at IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark",
            "language": "python3",
            "name": "python36"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}